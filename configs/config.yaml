seed: 42

paths:
  llm_name_or_path: "/data1/lvchangwei/LLM/llama3.2-cpt/llama3.2-instruct-cptv1/v9-20250919-113647/checkpoint-185" 
  output_dir: "/data1/chenyuxuan/Project/MSMLM/model/llama3.2-chem-sft-gnn/llm_gnn_nofreeze2"
  # 统一使用更清晰的命名，直接指向权重文件
  gnn_state_dict_path: "/data1/lvchangwei/GNN/Project/GVP/checkpoints_256_wo/gvp_weights_best.pt"
  # 我们之前的讨论中，mlp适配器是随训练的，如果需要预加载，可以添加：
  # gnn_mlp_state_dict_path: null 
  
tokens:
  mol_token: "<mol>"

# 将冻结配置放到 train 下，更符合逻辑
train:
  dataset_path: "/data1/lvchangwei/LLM/SFT_data/SFT_DATA.json"
  max_seq_length: 1024
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 8
  learning_rate: 2e-5
  num_train_epochs: 1
  logging_steps: 100
  save_steps: 1000
  eval_steps: 1000
  warmup_ratio: 0.03
  bf16: true
  gradient_checkpointing: true
  packing: false
  lr_scheduler_type: "cosine"
  max_retries: 3
  retry_backoff_sec: 30
  save_total_limit: 3
  
  # ★ 新增：控制模型部分的冻结
  freeze_llm: false # 冻结LLM本体，一般为false
  freeze_gnn: false # 冻结GNN编码器
  freeze_mol_adapter: false # 冻结GNN到LLM的适配器
  freeze_diffusion_adapter: true 
  freeze_diffusion: true 
  
network:
  proxy: "http://127.0.0.1:7899"

diffusion:
  diffusion:                  # = diffusion_encoder_config
    checkpoint_path: "/data1/chenyuxuan/Project/MSMLM/model/diffusion/pubchem_fullatom_cond_0806_v1/log/pubchem_fullatom_cond_0806_v1/checkpoints/last-v1.ckpt"
    device: "cuda:0"
    cond_dim: 3072          # 与你训练时的 cond_dim 保持一致
  adapter:                   # = diffusion_adapter_config（你的 diffusion_mlp）
    ckpt_path: "/data1/chenyuxuan/Project/MSMLM/model/diffusion_mlp/ckpt/diffusion_mlp_epoch1.pt"
  generation:
    num_nodes_lig: null      # 传给 LigandOnlyDDPM.generate_mol_from_embedding
    max_tries: 1             # 解析失败时是否重试（你要的话可以在代码里循环 N 次）